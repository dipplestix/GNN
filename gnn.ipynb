{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gcn import GCN\n",
    "from graphsage import GraphSAGE, GraphSAGE2\n",
    "from gat import MultiLayerGAT, GAT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_geometric.datasets as tg_datasets\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.utils import to_dense_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load the Cora dataset\n",
    "cora_dataset = tg_datasets.Planetoid(root='.', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "# Get the data object\n",
    "data = cora_dataset[0]\n",
    "\n",
    "# Get the feature matrix\n",
    "X = data.x\n",
    "\n",
    "# Get the labels\n",
    "labels = data.y\n",
    "\n",
    "# Get the train, validation, and test masks\n",
    "train_mask = data.train_mask\n",
    "val_mask = data.val_mask\n",
    "test_mask = data.test_mask\n",
    "\n",
    "# Get the edge index and convert it to a dense adjacency matrix\n",
    "adj = to_dense_adj(data.edge_index).squeeze(0)\n",
    "\n",
    "# Add self-loops and normalize the adjacency matrix\n",
    "adj = adj + torch.eye(adj.size(0))\n",
    "D = torch.diag(torch.sum(adj, dim=1)**(-0.5))\n",
    "adj_normalized = torch.matmul(torch.matmul(D, adj), D)\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# Move data to the device\n",
    "X = X.to(device)\n",
    "labels = labels.to(device)\n",
    "adj_normalized = adj_normalized.to(device)\n",
    "adj = adj.to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "val_mask = val_mask.to(device)\n",
    "test_mask = test_mask.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train(num_epochs, hidden_dim, num_layers, model_type, adj_matrix, aggregator=None):\n",
    "    input_dim = X.size(1)\n",
    "    output_dim = cora_dataset.num_classes\n",
    "    if model_type == GCN:\n",
    "        model = model_type(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "    elif model_type == GraphSAGE2:\n",
    "        model = model_type(input_dim, hidden_dim, output_dim).to(device)\n",
    "    elif model_type == GAT:\n",
    "        model = model_type(input_dim, hidden_dim, output_dim, 0.5, 0.2, 8).to(device)\n",
    "    else:\n",
    "        model = model_type(input_dim, hidden_dim, output_dim, num_layers, aggregator).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X, adj_matrix)\n",
    "\n",
    "        # Compute the loss only for the labeled nodes\n",
    "        loss = criterion(output[train_mask], labels[train_mask])\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, pred = torch.max(output[val_mask], dim=1)\n",
    "            correct = (pred == labels[val_mask]).sum().item()\n",
    "            accuracy = correct / val_mask.sum().item()\n",
    "            # if epoch % 100 == 99:\n",
    "            #     print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}, Validation accuracy: {accuracy:.4f}\")\n",
    "    # print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval(model, adj_matrix):\n",
    "    model.eval()\n",
    "    output = model(X, adj_matrix)\n",
    "    with torch.no_grad():\n",
    "        _, pred = torch.max(output[test_mask], dim=1)\n",
    "        correct = (pred == labels[test_mask]).sum().item()\n",
    "        accuracy = correct / test_mask.sum().item()\n",
    "        print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8040\n",
      "CPU times: user 1.07 s, sys: 1.13 s, total: 2.2 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = train(200, 128, 2, GCN, adj_normalized)\n",
    "eval(model, adj_normalized)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7430\n",
      "CPU times: user 1.09 s, sys: 85.3 ms, total: 1.17 s\n",
      "Wall time: 932 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = train(400, 64, 2, GraphSAGE, adj, 'mean')\n",
    "eval(model, adj)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7730\n",
      "CPU times: user 1.42 s, sys: 83.4 ms, total: 1.51 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = train(200, 64, 2, GraphSAGE, adj, 'pool')\n",
    "eval(model, adj)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipplestix/anaconda3/envs/1952q/lib/python3.10/site-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "model = train(200, 32, 2, GraphSAGE2, data.edge_index.to(device))\n",
    "eval(model, data.edge_index.to(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "def unsupervised_loss(embeddings, edge_index, num_neg_samples=5):\n",
    "    pos_score = torch.sum(embeddings[edge_index[0]] * embeddings[edge_index[1]], dim=-1)\n",
    "    pos_loss = F.logsigmoid(pos_score).mean()\n",
    "\n",
    "    neg_samples = torch.randint(0, embeddings.size(0), (num_neg_samples, edge_index.size(1)), device=device)\n",
    "    neg_score = torch.sum(embeddings[edge_index[0].view(-1, 1).repeat(1, num_neg_samples)].view(-1, embeddings.size(1)) * embeddings[neg_samples.view(-1)], dim=-1)\n",
    "    neg_loss = F.logsigmoid(-neg_score.view(num_neg_samples, -1)).mean()\n",
    "\n",
    "    return -pos_loss - neg_loss\n",
    "\n",
    "def train(data, adj, alpha=0.5):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # embeddings = model(data.x.to(device), data.edge_index.to(device))\n",
    "    embeddings = model(data.x.to(device), adj)\n",
    "    supervised_loss = F.cross_entropy(embeddings[data.train_mask], data.y[data.train_mask].to(device))\n",
    "    unsupervised_loss_val = unsupervised_loss(embeddings, data.edge_index.to(device))\n",
    "    loss = alpha * supervised_loss + (1 - alpha) * unsupervised_loss_val\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    embeddings = model(data.x.to(device), data.edge_index.to(device))\n",
    "    pred = embeddings.argmax(dim=1)\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        correct = pred[mask].eq(data.y[mask].to(device)).sum().item()\n",
    "        accs.append(correct / mask.sum().item())\n",
    "    return accs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7340\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.size(1)\n",
    "hidden_dim = 32\n",
    "output_dim = cora_dataset.num_classes\n",
    "# model = GraphSAGE2(input_dim, hidden_dim, output_dim).to(device)\n",
    "model = GraphSAGE(input_dim, hidden_dim, output_dim, 2, 'mean').to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "for e in range(200):\n",
    "    train(data, adj)\n",
    "eval(model, adj)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (attentions): ModuleList(\n",
      "    (0-1): 2 x GraphAttentionLayer(\n",
      "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
      "      (attention): Linear(in_features=32, out_features=1, bias=True)\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "  )\n",
      "  (out_att): GraphAttentionLayer(\n",
      "    (linear): Linear(in_features=32, out_features=7, bias=True)\n",
      "    (attention): Linear(in_features=14, out_features=1, bias=True)\n",
      "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 73.9 ms, total: 23.4 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "device = get_device()\n",
    "input_dim = X.size(1)\n",
    "hidden_dim = 16\n",
    "output_dim = cora_dataset.num_classes\n",
    "model = GAT(input_dim, hidden_dim, output_dim, 0.5, 0.2, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X, adj)\n",
    "\n",
    "    # Compute the loss only for the labeled nodes\n",
    "    loss = criterion(output[train_mask], labels[train_mask])\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8170\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output = model(X, adj)\n",
    "with torch.no_grad():\n",
    "    _, pred = torch.max(output[test_mask], dim=1)\n",
    "    correct = (pred == labels[test_mask]).sum().item()\n",
    "    accuracy = correct / test_mask.sum().item()\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "class GAT_MPNN(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads, n_layers):\n",
    "        super(GAT_MPNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Multi-head attention layers\n",
    "        self.attentions = torch.nn.ModuleList([GATConv(nfeat, nhid, heads=nheads, dropout=dropout) for _ in range(n_layers - 1)])\n",
    "\n",
    "        # Output attention layer\n",
    "        self.out_att = GATConv(nhid * nheads, nclass, heads=1, concat=False, dropout=dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Message passing and node updates\n",
    "        for attention_layer in self.attentions:\n",
    "            x = F.elu(attention_layer(x, edge_index))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Readout function\n",
    "        x = self.out_att(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 983 ms, sys: 96.2 ms, total: 1.08 s\n",
      "Wall time: 974 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data.to(device)\n",
    "\n",
    "device = get_device()\n",
    "input_dim = X.size(1)\n",
    "hidden_dim = 32\n",
    "output_dim = cora_dataset.num_classes\n",
    "model = GAT_MPNN(input_dim, hidden_dim, output_dim, 0.5, 0.2, 4, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "\n",
    "    # Compute the loss only for the labeled nodes\n",
    "    loss = criterion(output[train_mask], labels[train_mask])\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output = model(data)\n",
    "with torch.no_grad():\n",
    "    _, pred = torch.max(output[test_mask], dim=1)\n",
    "    correct = (pred == labels[test_mask]).sum().item()\n",
    "    accuracy = correct / test_mask.sum().item()\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 10556])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3, 4, 4,  ..., 3, 3, 3], device='cuda:0')"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2708, 2708])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dense_adj(data.edge_index).squeeze(0).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "class GAT_MPNN2(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads, n_layers):\n",
    "        super(GAT_MPNN2, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Multi-head attention layers\n",
    "        self.attentions = torch.nn.ModuleList([GATConv(nfeat, nhid, heads=nheads, dropout=dropout) for _ in range(n_layers - 1)])\n",
    "\n",
    "        # Output attention layer\n",
    "        self.out_att = GATConv(nhid * nheads, nclass, heads=1, concat=False, dropout=dropout)\n",
    "\n",
    "    def message(self, x, edge_index):\n",
    "        messages = []\n",
    "        for attention_layer in self.attentions:\n",
    "            messages.append(attention_layer(x, edge_index))\n",
    "        return messages\n",
    "\n",
    "    def update(self, x, messages):\n",
    "        x = torch.cat(messages, dim=1)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "    def readout(self, x, edge_index):\n",
    "        x = F.elu(self.out_att(x, edge_index))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Message passing\n",
    "        messages = self.message(x, edge_index)\n",
    "\n",
    "        # Node updates\n",
    "        x = self.update(x, messages)\n",
    "\n",
    "        # Readout function\n",
    "        x = self.readout(x, edge_index)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-5.4318e-03,  1.1499e-03, -4.9245e-03,  ...,  3.2788e-03,\n",
      "          7.5543e-03,  8.8980e-03],\n",
      "        [ 5.4508e-03, -9.2905e-04,  1.8591e-03,  ..., -5.8226e-03,\n",
      "          1.7247e-03, -9.2903e-04],\n",
      "        [-2.6059e-03,  2.4326e-04,  8.5951e-03,  ..., -6.8162e-03,\n",
      "          5.2241e-03, -4.6661e-03],\n",
      "        ...,\n",
      "        [-9.5754e-03, -2.7873e-02, -6.4762e-03,  ..., -2.9698e-03,\n",
      "          1.3995e-02,  3.2855e-03],\n",
      "        [ 5.8869e-03, -1.3036e-03,  3.0231e-03,  ...,  1.6307e-04,\n",
      "         -5.5354e-03, -9.3102e-03],\n",
      "        [-4.7539e-03, -6.1458e-05,  4.8899e-03,  ...,  1.1061e-03,\n",
      "         -5.1247e-03, -7.3336e-03]], device='cuda:0', grad_fn=<AddBackward0>)]\n",
      "torch.Size([2708, 128])\n",
      "CPU times: user 127 ms, sys: 0 ns, total: 127 ms\n",
      "Wall time: 14.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data.to(device)\n",
    "\n",
    "device = get_device()\n",
    "input_dim = X.size(1)\n",
    "hidden_dim = 32\n",
    "output_dim = cora_dataset.num_classes\n",
    "model = GAT_MPNN2(input_dim, hidden_dim, output_dim, 0.5, 0.2, 4, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "\n",
    "    # Compute the loss only for the labeled nodes\n",
    "    loss = criterion(output[train_mask], labels[train_mask])\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
